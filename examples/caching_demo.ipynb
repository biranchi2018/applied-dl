{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "caching-demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_oO-8bBz8Ge",
        "colab_type": "text"
      },
      "source": [
        "## The speed of your input pipeline counts\n",
        "Here's a quick tip if you're using [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview) to import your datasets. Use .cache() when writing your input pipeline, otherwise you'll be reading data off disk batch-by-batch, which can increase the training time of your model by **2x** (more if you're using GPUs). \n",
        "\n",
        "In this notebook, you'll create two identical models:\n",
        "\n",
        "* The first will train about **2x** slower than the second.\n",
        "* The only difference will be the input pipeline.\n",
        "\n",
        "At the end of the notebook are resources you can use to learn more about writing efficient input pipelines.  \n",
        "\n",
        "### Background: you may be used to loading toy datasets into memory\n",
        "\n",
        "If you've previously worked with toy datasets like MNIST and libraries like Keras or Scikit-learn, you may know they import small datasets into memory by default. For example, this code:\n",
        "\n",
        "```\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "```\n",
        "\n",
        "downloads MNIST and returns NumPy arrays, as you would expect.\n",
        "\n",
        "### TensorFlow Datasets downloads data to disk by default\n",
        "\n",
        "[TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview) downloads datasets to disk. This makes sense (a bunch are huge). After you've downloaded a dataset, you need to write an [input pipeline](https://www.tensorflow.org/beta/tutorials/load_data/images) to read it, preprocess it, and feed it to your model. You can do that using tf.data - which at its best can be significantly faster than NumPy alone - but it does have a learning curve. This doesn't have to be too complicated, though. If you're working with small datasets that fit into memory, you can simply use .cache() for better performance, so they work as you'd expect.\n",
        "\n",
        "\n",
        "For example, this code downloads a dataset to disk, and then reads it back batch by batch. This is probably not what you want:\n",
        "\n",
        "```\n",
        "# download and prepare a dataset\n",
        "dataset = tfds.load(name='mnist', as_supervised=True)\n",
        "train_ds = dataset['train'].map(format_example)\n",
        "oops = train_ds.shuffle(shuffle_size).batch(batch_size)\n",
        "\n",
        "# iterate over it\n",
        "for i, batch in enumerate(oops):\n",
        "  # do something with the batch\n",
        "\n",
        "```\n",
        "\n",
        "Each batch in the example above is loaded off disk when needed. Even simply iterating over this dataset will take a few seconds.\n",
        "\n",
        "On the other hand, this code:\n",
        "\n",
        "```\n",
        "# use caching\n",
        "better = train_ds.cache().shuffle(shuffle_size).batch(batch_size)\n",
        "```\n",
        "\n",
        "Will keep an in_memory cache of the data. That means every epoch after the first will run as fast as you'd expect. Note that the behavior of ```.cache()``` was just updated, which is why we'll install the nightly branch below.\n",
        "\n",
        "For small datasets, you can also use a recently added ```in_memory``` flag, like this:\n",
        "\n",
        "```\n",
        "dataset = tfds.load(name='mnist', as_supervised=True, in_memory=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6LiqVUo4dWE",
        "colab_type": "text"
      },
      "source": [
        "### Install the nightly branch of TF 2.0 beta\n",
        "\n",
        "This notebook uses an update in the nightly branch. Notice we're installing a specific day (rather than the latest, which you can install with ```!pip install tf-nightly-2.0-preview```). That's to make this demo reproducible. Also, we're using the CPU version here. If you wanted the GPU version, you could use ```!pip install tf-nightly-gpu-2.0-preview```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2uRrd3l4kPh",
        "colab_type": "text"
      },
      "source": [
        "### Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoEmz20w4W2Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6031b8f7-3165-4df1-fdc7-ae141663e353"
      },
      "source": [
        "!pip install tf-nightly-2.0-preview==2.0.0.dev20190815 -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 88.5MB 1.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 19.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.1MB 32.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 42.7MB/s \n",
            "\u001b[?25h  Building wheel for opt-einsum (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilVKkcgF4qSZ",
        "colab_type": "code",
        "outputId": "469ec048-b2f0-4126-b269-966b5ea060c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "import time\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "SHUFFLE_BUFFER_SIZE = 10000"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-dev20190815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ywghWt44lxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If this fails, you may need to restart your runtime after installing \n",
        "# a new version of TF above (Runtime -> restart)\n",
        "assert tf.__version__ == \"2.0.0-dev20190815\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghZ9Zicm4zzV",
        "colab_type": "text"
      },
      "source": [
        "### Create a tiny model\n",
        "We'll train two identical copies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHb6PQkG472M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tiny_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6VAmbfw51X3",
        "colab_type": "text"
      },
      "source": [
        "### Download a small dataset using TensorFlow Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLjBWXJF506D",
        "colab_type": "code",
        "outputId": "969c2b32-6f62-4a04-f0dc-be96b12c4603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "dataset, info = tfds.load(name='mnist', as_supervised=True, with_info=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist (11.06 MiB) to /root/tensorflow_datasets/mnist/1.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0816 11:31:04.871948 140158811002752 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "W0816 11:31:09.319082 140158811002752 dataset_builder.py:439] Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCGROyf-HGvu",
        "colab_type": "text"
      },
      "source": [
        "### A little preprocessing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK9OZgEQ56cD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_example(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHjN_B0vMN8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = dataset['train'].map(format_example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rshBn6Tc6cLp",
        "colab_type": "text"
      },
      "source": [
        "### A slow input pipeline\n",
        "\n",
        "Oops! This will read data batch-by-batch off disk, and slow down training by about 2x (or more!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQukbUo66bh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slow_ds = train_ds.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn3E_PSQ6qE7",
        "colab_type": "text"
      },
      "source": [
        "### A faster pipeline\n",
        "This one uses .cache() to keep images in memory. The speed for the first epoch will be about the same as the slow pipeline (while the cache is being built). Afterwards, the model will train much faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRS2FWUB6r0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fast_ds = train_ds.cache().shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyWDlg-x7Cnf",
        "colab_type": "text"
      },
      "source": [
        "### Compare the two\n",
        "Compare the time taken for the first and subsequent epochs, w/ the fast and slow input pipeline. The first epoch should be about the same (while the cache is being built), the second and third will be much faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nywLgOby7GnE",
        "colab_type": "code",
        "outputId": "8bedcbc6-87d6-4bc1-bbf3-bdc6d727f6e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "tiny_model().fit(slow_ds, epochs=3)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0816 11:31:11.828142 140158811002752 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:466: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Apply a constraint manually following the optimizer update step.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 9.5306\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 6.1226\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 5.7147\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7902fec828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdP9XuLs-kEv",
        "colab_type": "code",
        "outputId": "1ea52bea-888d-45b6-a1e4-85321db6386f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "tiny_model().fit(fast_ds, epochs=3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 10.1800\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 6.1128\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.8007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f790293f588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxOHH9H10aMI",
        "colab_type": "text"
      },
      "source": [
        "When using a GPU, the performance difference will be greater. \n",
        "\n",
        "\n",
        "### Next steps\n",
        "\n",
        "* To learn more about writing efficient input pipelines using tf.data (and how to cache expensive preprocessing, and datasets that do not fit in to memory) see this [guide](https://www.tensorflow.org/beta/tutorials/load_data/images). That guide also has a nice benchmark utility you can use to iterate over datasets (without training a model) to see the performance.\n",
        "\n",
        "* For future work in progress to make this all easier, see this [Request for Comments](https://github.com/keras-team/governance/pull/6) on the Keras Preprocessing updates. "
      ]
    }
  ]
}